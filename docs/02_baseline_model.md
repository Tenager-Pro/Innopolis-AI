# Документация по базовым моделям со статистическим анализом

## Обзор
Модуль для создания, обучения и оценки базовых моделей машинного обучения для задачи предсказания оттока клиентов. Включает статистический анализ производительности моделей и сравнение их эффективности.

## Назначение
Создание эталонных (baseline) моделей для последующего сравнения с более сложными подходами. Модуль выполняет:
1. Загрузку подготовленных данных
2. Обучение трех типов моделей
3. Оценку производительности с использованием различных метрик
4. Статистический анализ результатов
5. Визуализацию сравнения моделей

## Действия

1. Инициализация и загрузка данных
    Назначение: Вывод заголовка анализа и загрузка подготовленных данных из базы данных.

    Процесс:
        Создание подключения к PostgreSQL
        Загрузка данных из таблицы ml_ready_features
        Подготовка матрицы признаков (X) и целевой переменной (y)
        Удаление ненужных столбцов: Churn (целевая переменная) и CustomerID (идентификатор)

    Выходные данные:
        Форма данных (количество строк и столбцов)
        Распределение целевой переменной
        Процент оттока (churn rate)

2. Разделение данных на обучающую и тестовую выборки
    Параметры:
        test_size=0.2: 20% данных для тестирования
        random_state=42: Фиксированное случайное состояние для воспроизводимости
        stratify=y: Стратификация по целевой переменной для сохранения распределения

    Результат:
        Размеры обучающей и тестовой выборок
        Процент оттока в каждой выборке

3. Обучение базовых моделей
    Модели включают:
        Logistic Regression (Логистическая регрессия)
        Decision Tree (Дерево решений)
        Random Forest (Случайный лес)

    Процесс обучения для каждой модели:
        Масштабирование признаков (только для логистической регрессии)
        Обучение модели на тренировочных данных
        Предсказание на тестовых данных
        Расчет метрик качества

4. Метрики оценки производительности
    Основные метрики:
        Accuracy (Точность)
        AUC-ROC
        Average Precision (Средняя точность)
        Кросс-валидация

5. Визуальное сравнение моделей
    Создаваемые графики:
        ROC Curves (Кривые ROC)
        Precision-Recall Curves (Кривые Precision-Recall)
        Confusion Matrix (Матрица ошибок)
        Performance Comparison (Сравнение производительности)
        Cross-Validation Results (Результаты кросс-валидации)
        Feature Importance (Важность признаков)


6. Анализ ошибок
    Цели:
        Определение паттернов ошибок
        Анализ согласия между моделями
        Выявление сложных для классификации случаев

    Анализируемые аспекты:
        Количество ошибочных предсказаний
        Случаи, где все модели ошибаются
        Случаи, где все модели правы

7. Статистическая проверка значимости
    Bootstrap-анализ:
        Цель: Оценка доверительных интервалов для метрик
        Метод: 1000 итераций повторной выборки с возвращением
        Рассчитываемые метрики:
            Среднее значение AUC и Accuracy
            95% доверительные интервалы

    Статистические тесты:
        Парный t-тест (ttest_rel)
        Сравнение: AUC моделей по результатам кросс-валидации
        яКритерий значимости: p-value < 0.05

8. Выбор и сохранение лучшей модели
    Критерии выбора:
        Наибольшее значение AUC
        Стабильность (результаты кросс-валидации)
        Интерпретируемость

    Сохранение модели:
        Использование библиотеки joblib
        Сохранение в директорию ../models/baseline/
        Формат: .pkl (pickle)